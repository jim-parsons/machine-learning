{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 多输入通道和多输出通道\n",
    "\n",
    "> **真实彩色图像中,除高`h`和宽`w`2个维度外,还有RGB(红,绿,蓝)3个颜色通道,可用 $3 \\times h \\times w$表示,此时将大小为3的这一维度成为通道(channel)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 多输入通道\n",
    "\n",
    "> 1. **假设输入数据通道数为$c_i$,那卷积核同样为$c_i$,且大小为$k_h \\times k_w$,此时卷积核形状为$c_i \\times k_h \\times k_w$**\n",
    "> 2. **在输入数据和卷积核对应的每个通道上,进行互相关运算,最后将$c_i$个互相关运算的二维输出按通道相加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch.utils as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 分别沿着X和K的第0维（通道维）分别计算在相加\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "print(X.shape)\n",
    "print(K.shape)\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 多输出通道\n",
    "\n",
    "> 1. **设卷积核的输入和输出通道分别为$c_i$和$c_o$,大小为$k_h \\times k_w$**\n",
    "> 2. **为每个输出通道分别创建形状为$c_i \\times k_h \\times k_w$的卷积核,将他们在输出通道上连结,此时卷积核的形状为$c_o \\times c_i \\times k_h \\times k_w$, 即（输出通道，输入通道，高， 宽）**\n",
    "> 3. **每个输出通道上的结果,由上述卷积核在该输出通道上的核数组与整个输入数组计算得来**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K第0维遍历,每次与X做互相关运算,最后结果使用stack结合在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用K, K+1, K+2 连结在一起构造一个输出通道为3的卷积核\n",
    "K = torch.stack([K, K+1, K+2])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个通道的结果与上面单输出结果一致\n",
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3  1 X 1 卷积层\n",
    "\n",
    "> 1. **主要用于通道维计算,此时输入和输出具有相同的宽和高**\n",
    "> 2. **输出元素等于输入元素在相同宽、高位置上元素在不同位置的按权累加**\n",
    "> 3. **假设将通道维当做特征维,将宽高维度上的元素当做样本,那么1X1卷积的作用等价于全连接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)\n",
    "    return Y.view(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(3, 3, 3)\n",
    "# K此时是2输出通道,3输入通道,1x1\n",
    "K = torch.rand(2, 3, 1, 1)\n",
    "\n",
    "# 变换为 (2, 3) . (3, 9) => (2, 9)\n",
    "# 最后在变为(2, 3, 3)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "# 这个为了说明两者效果一致\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1673, 0.7500, 0.8406],\n",
       "        [0.4102, 0.1670, 0.8739]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.view(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7067, 0.5082, 0.2194, 0.4368, 0.7227, 0.4741, 0.3642, 0.7392, 0.7249],\n",
       "        [0.9680, 0.8728, 0.1763, 0.8929, 0.5334, 0.5359, 0.7170, 0.6469, 0.0583],\n",
       "        [0.0072, 0.5873, 0.9747, 0.9591, 0.5170, 0.1785, 0.1421, 0.3002, 0.1103]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.view(3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
